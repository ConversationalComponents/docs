{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"What is CoCo? Conversational Components make chatbot building easier by deconstructing conversations into components. All components hold context over multiple turns of conversation to better engage your users, with logic wired into the conversational flow. All you have to do is incorporate them into your bots. It\u2019s time to make the development of conversational A.I. a collaborative process. When you build on reusable and customizable parts, you create better chatbots to make conversation easy. You\u2019ll be able to stack a conversation with pre-built dialogue blocks. Each of these blocks maintains user context throughout the conversation. They\u2019re also reusable and customizable, saving you precious time by eliminating the need to create a dialogue management system from scratch for every new bot you build. And the best part? CoCos are simple to implement into any bot framework! For Chatbot Developers It's really easy to use Conversational Components in your chatbots. With CoCo, you can call components through a simple unified, REST format that is easy to embed in your chatbot. Moreover, you can view all of the components you are using in your user profile, which monitors the number of API requests, latency, and error rates, among other metrics. For more on using components, check out the Basics - Your First Component Call section or our CoCos for Developers page. For Component Vendors If you\u2019ve already built excellent components of your own, we make it simple for you to distribute and monetize it. Adding your component to CoCo's Marketplace offers you several benefits. You\u2019ll get instant exposure to our growing user base, a search-engine-optimized profile page for your component, as well as features like user management and billing services. For more on adding your component, visit our Adding & Managing components - Getting Started section or check out our Components Providers page.","title":"About"},{"location":"#what-is-coco","text":"Conversational Components make chatbot building easier by deconstructing conversations into components. All components hold context over multiple turns of conversation to better engage your users, with logic wired into the conversational flow. All you have to do is incorporate them into your bots. It\u2019s time to make the development of conversational A.I. a collaborative process. When you build on reusable and customizable parts, you create better chatbots to make conversation easy. You\u2019ll be able to stack a conversation with pre-built dialogue blocks. Each of these blocks maintains user context throughout the conversation. They\u2019re also reusable and customizable, saving you precious time by eliminating the need to create a dialogue management system from scratch for every new bot you build. And the best part? CoCos are simple to implement into any bot framework!","title":"What is CoCo?"},{"location":"#for-chatbot-developers","text":"It's really easy to use Conversational Components in your chatbots. With CoCo, you can call components through a simple unified, REST format that is easy to embed in your chatbot. Moreover, you can view all of the components you are using in your user profile, which monitors the number of API requests, latency, and error rates, among other metrics. For more on using components, check out the Basics - Your First Component Call section or our CoCos for Developers page.","title":"For Chatbot Developers"},{"location":"#for-component-vendors","text":"If you\u2019ve already built excellent components of your own, we make it simple for you to distribute and monetize it. Adding your component to CoCo's Marketplace offers you several benefits. You\u2019ll get instant exposure to our growing user base, a search-engine-optimized profile page for your component, as well as features like user management and billing services. For more on adding your component, visit our Adding & Managing components - Getting Started section or check out our Components Providers page.","title":"For Component Vendors"},{"location":"CCML/","text":"CCML => CoCo Speech Synthesis Markup Language A cross platform speech synthesis markup language. <break> Set pause at the conversation. Channels Supported Phone Amazon Alexa Google Assistant ZOOM Attributes strength - none: Remove a pause. x-weak: Remove a pause same as none. weak: Treat adjacent words as if separated by a single comma (equivalent to medium). medium: Treat adjacent words as if separated by a single comma. strong: Make a sentence break. x-strong: Make a paragraph break. time - Sets the length of the break by seconds or milliseconds (e.g. \"3s\" or \"250ms\"). Example Lakritz is tasty <break time=\"3s\"/> Nooot! <say-as> The tag lets you indicate information about the type of text construct that is contained within the tag. Channels Supported Phone Amazon Alexa Google Assistant ZOOM Attributes interpret-as - characters, spell-out: Spell out each letter. cardinal, number: Interpret the value as a cardinal number. ordinal: Interpret the value as an ordinal number. fraction: Interpret the value as a fraction. This works for both common fractions (such as 3/20) and mixed fractions (such as 1+1/2). unit: Interpret a value as a measurement. The value should be either a number or fraction followed by a unit (with no space in between) or just a unit. date: Interpret the value as a date. Specify the format with the format attribute. time: Interpret a value such as 1'21\" as duration in minutes and seconds. telephone: Interpret a value as a 7-digit or 10-digit telephone number. This can also handle extensions (for example, 2025551212x345). expletive: \"Bleep\" out the content inside the tag. Example <say-as interpret-as=\"cardinal\">12345</say-as> <p> Represents a paragraph in speech. Channels Supported Phone Amazon Alexa Google Assistant ZOOM Example <p>This is the first paragraph.</p> <p>This is the second paragraph.</p> <s> Represents a sentence in speech. Channels Supported Phone Amazon Alexa Google Assistant ZOOM Example <s>This is the first sentence.</s> <s>This is the second sentence.</s> <prosody> Used to customize the pitch, speaking rate, and volume of text contained by the element. Channels Supported Phone Amazon Alexa Google Assistant ZOOM Attributes rate - Modify the rate of the speech - slow medium fast pitch - Raise or lower the tone (pitch) of the speech - slow medium fast volume - Change the volume for the speech - silent x-soft soft medium loud x-loud Example <prosody volume=\"x-loud\">Louder volume for this sentence.</prosody>. <prosody rate=\"slow\">I speak quite slowly</prosody>. <emphasis> Emphasis changes rate and volume of the speech. More emphasis is spoken louder and slower. Less emphasis is quieter and faster. Channels Supported Phone Amazon Alexa Google Assistant ZOOM Attributes level - strong: Increase the volume and slow down the speaking rate so the speech is louder and slower. moderate: Increase the volume and slow down the speaking rate, but not as much as when set to strong. This is used as a default if level is not provided. reduced: Decrease the volume and speed up the speaking rate. The speech is softer and faster. Example Hey you, <emphasis level=\"strong\">come here!</emphasis> <sub> Indicate that the text in the alias attribute value replaces the contained text for pronunciation. Channels Supported Phone Amazon Alexa Google Assistant ZOOM Attributes alias - The word or phrase to speak in place of the tagged text. Example <sub alias=\"Speech Synthesis Markup Language\">ssml</sub> <phoneme> Provides a phonemic/phonetic pronunciation for the contained text. People may pronounce some words differently. Channels Supported Phone Amazon Alexa ZOOM Attributes and Examples Amazon Alexa phoneme tag description <voice> Use the voice tag to speak the text with the specified Amazon Polly voice. Channels Supported Phone Amazon Alexa ZOOM Attributes name - Polly voice ID ( List of voice IDs ) Example <voice name=\"Amy\">My name is Amy, darling.</voice>. <language> Use language to specify the language model and rules to speak the tagged content as if it were written in the language specified by the xml:lang attribute. Channels Supported Phone Amazon Alexa ZOOM Attributes xml:lang - de-DE en-AU en-CA en-GB en-IN en-US es-ES es-MX es-US fr-CA fr-FR hi-IN it-IT ja-JP pt-BR Example <language xml:lang=\"fr-FR\">J'adore chanter</language> <part-of-speech> Similar to say-as, this tag customizes the pronunciation of words by specifying the word's part of speech. Channels Supported Phone Amazon Alexa ZOOM Attributes role - amazon:VB: Interpret the word as a verb (present simple). amazon:VBD: Interpret the word as a past participle. amazon:NN: Interpret the word as a noun. Example I really like to <part-of-speech role=\"amazon:VB\">eat</part-of-speech> pizza. <domain> Applies different speaking styles to the speech. The styles are curated text-to-speech voices that use different variations of intonation, emphasis, pausing, and other techniques to match the speech to the content. Channels Supported Amazon Alexa ZOOM Attributes name - conversational \u2013 Style voices to sound more conversational and less formal, more like how people sound when they speak to friends and family. The conversational style is available in English (US), Italian (IT), and Japanese (JP) skills. You can also use this style with Amazon Polly voices. For Amazon Polly, conversational requires the <voice> tag and the Matthew or Joanna voices. long-form \u2013 Style the speech for long-form content such as podcasts, articles, and blogs. The long-form style can't be used with the voice tag. The long-form style is available in English (US) skills. music \u2013 Style the speech for talking about music, video, or other multi-media content. The music style can't be used with the voice tag. The music style is available in English (US), English (CA), and English (UK) skills. news \u2013 Style the speech similar to what you hear when listening to the news on the radio or television. The news style can be combined with the voice tag and the Matthew, Joanna, and Lupe voices. The news style is available in English (US) and English (AU) skills. Example <domain name=\"news\"> Here are the latest new about conversational AI and voice. </domain> <effect> Applies specific effects to the speech. Channels Supported Amazon Alexa ZOOM Attributes name - whispered - Applies a whispering effect to the speech. Example <effect name=\"whispered\">I am whispering this.</effect> <emotion> The emotion tag causes Alexa to express emotion when speaking. Channels Supported Amazon Alexa ZOOM Attributes name - The name of the emotion to apply to the speech. - excited disappointed intensity - The intensity or strength of the emotion to express. - low medium high Example <emotion name=\"excited\" intensity=\"high\"> This is unbelievable! </emotion> <speak> This is the root element of an SSML document. Channels Supported Amazon Alexa Google Assistant ZOOM Example <speak> SSML content </speak> <audio> The audio tag lets you provide the URL for an MP3 file that the service can play while rendering a response. Channels Supported Amazon Alexa Google Assistant ZOOM Attributes src - A URI referring to the audio media source. Supported protocol is https. Example <audio src=\"https://some-url.com/soundfile.mp3\" /> <mark> An empty element that places a marker into the text or tag sequence. It can be used to reference a specific location in the sequence or to insert a marker into an output stream for asynchronous notification. Channels Supported Google Assistant Attributes name - Mark name. Example Go from <mark name=\"here\"/> here, to <mark name=\"there\"/> there! <media> Represents a media layer within a <parallel> or <sequential> element. The allowed content of a <media> element is an SSML <speak> or <audio> element. The following table describes the valid attributes for a <media> element. Channels Supported Google Assistant Attributes xml:id - A unique XML identifier for this element. Encoded entities are not supported. The allowed identifier values match the regular expression \"([-_#]|\\p{L}|\\p{D})+\". See XML-ID for more information. begin - The beginning time for this media container. Ignored if this is the root media container element (treated the same as the default of \"0\"). See the Time specification section below for valid string values. end - A specification for the ending time for this media container. See the Time specification section below for valid string values. repeatCount - A Real Number specifying how many times to insert the media. Fractional repetitions aren't supported, so the value will be rounded to the nearest integer. Zero is not a valid value and is therefore treated as being unspecified and has the default value in that case. repeatDur - A TimeDesignation that is a limit on the duration of the inserted media. If the duration of the media is less than this value, then playback ends at that time. soundLevel - Adjust the sound level of the audio by soundLevel decibels. Maximum range is +/-40dB but actual range may be effectively less, and output quality may not yield good results over the entire range. fadeInDur - A TimeDesignation over which the media will fade in from silent to the optionally-specified soundLevel. If the duration of the media is less than this value, the media will be mid-fade in at the end of playback. fadeOutDur - A TimeDesignation over which the media will fade out from the optionally-specified soundLevel until it is silent. If the duration of the media is less than this value, the media will be mid-fade out at the beginning of playback. Example <media xml:id=\"question\" begin=\"0.5s\"> <speak>Who invented the Internet?</speak> </media> <parallel> A parallel media container that allows you to play multiple media elements at once. The only allowed content is a set of one or more <parallel>, <sequential>, and <media> elements. The order of the <media> elements is not significant. Channels Supported Google Assistant Example <parallel> <media xml:id=\"question\" begin=\"0.5s\"> <speak>Who invented the Internet?</speak> </media> <media xml:id=\"answer\" begin=\"question.end+2.0s\"> <speak>The Internet was invented by cats.</speak> </media> </parallel> <sequential> A sequential media container that allows you to play media elements one after another. The only allowed content is a set of one or more <sequential>, <parallel>, and <media> elements. The order of the media elements is the order in which they are rendered. Channels Supported Google Assistant Example <sequential> <media begin=\"0.5s\"> <speak>Who invented the Internet?</speak> </media> <media begin=\"2.0s\"> <speak>The Internet was invented by cats.</speak> </media> </sequential>","title":"CCML"},{"location":"CCML/#ccml-coco-speech-synthesis-markup-language","text":"A cross platform speech synthesis markup language.","title":"CCML =&gt; CoCo Speech Synthesis Markup Language"},{"location":"CCML/#break","text":"Set pause at the conversation.","title":"&lt;break&gt;"},{"location":"CCML/#channels-supported","text":"Phone Amazon Alexa Google Assistant ZOOM","title":"Channels Supported"},{"location":"CCML/#attributes","text":"strength - none: Remove a pause. x-weak: Remove a pause same as none. weak: Treat adjacent words as if separated by a single comma (equivalent to medium). medium: Treat adjacent words as if separated by a single comma. strong: Make a sentence break. x-strong: Make a paragraph break. time - Sets the length of the break by seconds or milliseconds (e.g. \"3s\" or \"250ms\").","title":"Attributes"},{"location":"CCML/#example","text":"Lakritz is tasty <break time=\"3s\"/> Nooot!","title":"Example"},{"location":"CCML/#say-as","text":"The tag lets you indicate information about the type of text construct that is contained within the tag.","title":"&lt;say-as&gt;"},{"location":"CCML/#channels-supported_1","text":"Phone Amazon Alexa Google Assistant ZOOM","title":"Channels Supported"},{"location":"CCML/#attributes_1","text":"interpret-as - characters, spell-out: Spell out each letter. cardinal, number: Interpret the value as a cardinal number. ordinal: Interpret the value as an ordinal number. fraction: Interpret the value as a fraction. This works for both common fractions (such as 3/20) and mixed fractions (such as 1+1/2). unit: Interpret a value as a measurement. The value should be either a number or fraction followed by a unit (with no space in between) or just a unit. date: Interpret the value as a date. Specify the format with the format attribute. time: Interpret a value such as 1'21\" as duration in minutes and seconds. telephone: Interpret a value as a 7-digit or 10-digit telephone number. This can also handle extensions (for example, 2025551212x345). expletive: \"Bleep\" out the content inside the tag.","title":"Attributes"},{"location":"CCML/#example_1","text":"<say-as interpret-as=\"cardinal\">12345</say-as>","title":"Example"},{"location":"CCML/#p","text":"Represents a paragraph in speech.","title":"&lt;p&gt;"},{"location":"CCML/#channels-supported_2","text":"Phone Amazon Alexa Google Assistant ZOOM","title":"Channels Supported"},{"location":"CCML/#example_2","text":"<p>This is the first paragraph.</p> <p>This is the second paragraph.</p>","title":"Example"},{"location":"CCML/#s","text":"Represents a sentence in speech.","title":"&lt;s&gt;"},{"location":"CCML/#channels-supported_3","text":"Phone Amazon Alexa Google Assistant ZOOM","title":"Channels Supported"},{"location":"CCML/#example_3","text":"<s>This is the first sentence.</s> <s>This is the second sentence.</s>","title":"Example"},{"location":"CCML/#prosody","text":"Used to customize the pitch, speaking rate, and volume of text contained by the element.","title":"&lt;prosody&gt;"},{"location":"CCML/#channels-supported_4","text":"Phone Amazon Alexa Google Assistant ZOOM","title":"Channels Supported"},{"location":"CCML/#attributes_2","text":"rate - Modify the rate of the speech - slow medium fast pitch - Raise or lower the tone (pitch) of the speech - slow medium fast volume - Change the volume for the speech - silent x-soft soft medium loud x-loud","title":"Attributes"},{"location":"CCML/#example_4","text":"<prosody volume=\"x-loud\">Louder volume for this sentence.</prosody>. <prosody rate=\"slow\">I speak quite slowly</prosody>.","title":"Example"},{"location":"CCML/#emphasis","text":"Emphasis changes rate and volume of the speech. More emphasis is spoken louder and slower. Less emphasis is quieter and faster.","title":"&lt;emphasis&gt;"},{"location":"CCML/#channels-supported_5","text":"Phone Amazon Alexa Google Assistant ZOOM","title":"Channels Supported"},{"location":"CCML/#attributes_3","text":"level - strong: Increase the volume and slow down the speaking rate so the speech is louder and slower. moderate: Increase the volume and slow down the speaking rate, but not as much as when set to strong. This is used as a default if level is not provided. reduced: Decrease the volume and speed up the speaking rate. The speech is softer and faster.","title":"Attributes"},{"location":"CCML/#example_5","text":"Hey you, <emphasis level=\"strong\">come here!</emphasis>","title":"Example"},{"location":"CCML/#sub","text":"Indicate that the text in the alias attribute value replaces the contained text for pronunciation.","title":"&lt;sub&gt;"},{"location":"CCML/#channels-supported_6","text":"Phone Amazon Alexa Google Assistant ZOOM","title":"Channels Supported"},{"location":"CCML/#attributes_4","text":"alias - The word or phrase to speak in place of the tagged text.","title":"Attributes"},{"location":"CCML/#example_6","text":"<sub alias=\"Speech Synthesis Markup Language\">ssml</sub>","title":"Example"},{"location":"CCML/#phoneme","text":"Provides a phonemic/phonetic pronunciation for the contained text. People may pronounce some words differently.","title":"&lt;phoneme&gt;"},{"location":"CCML/#channels-supported_7","text":"Phone Amazon Alexa ZOOM","title":"Channels Supported"},{"location":"CCML/#attributes-and-examples","text":"Amazon Alexa phoneme tag description","title":"Attributes and Examples"},{"location":"CCML/#voice","text":"Use the voice tag to speak the text with the specified Amazon Polly voice.","title":"&lt;voice&gt;"},{"location":"CCML/#channels-supported_8","text":"Phone Amazon Alexa ZOOM","title":"Channels Supported"},{"location":"CCML/#attributes_5","text":"name - Polly voice ID ( List of voice IDs )","title":"Attributes"},{"location":"CCML/#example_7","text":"<voice name=\"Amy\">My name is Amy, darling.</voice>.","title":"Example"},{"location":"CCML/#language","text":"Use language to specify the language model and rules to speak the tagged content as if it were written in the language specified by the xml:lang attribute.","title":"&lt;language&gt;"},{"location":"CCML/#channels-supported_9","text":"Phone Amazon Alexa ZOOM","title":"Channels Supported"},{"location":"CCML/#attributes_6","text":"xml:lang - de-DE en-AU en-CA en-GB en-IN en-US es-ES es-MX es-US fr-CA fr-FR hi-IN it-IT ja-JP pt-BR","title":"Attributes"},{"location":"CCML/#example_8","text":"<language xml:lang=\"fr-FR\">J'adore chanter</language>","title":"Example"},{"location":"CCML/#part-of-speech","text":"Similar to say-as, this tag customizes the pronunciation of words by specifying the word's part of speech.","title":"&lt;part-of-speech&gt;"},{"location":"CCML/#channels-supported_10","text":"Phone Amazon Alexa ZOOM","title":"Channels Supported"},{"location":"CCML/#attributes_7","text":"role - amazon:VB: Interpret the word as a verb (present simple). amazon:VBD: Interpret the word as a past participle. amazon:NN: Interpret the word as a noun.","title":"Attributes"},{"location":"CCML/#example_9","text":"I really like to <part-of-speech role=\"amazon:VB\">eat</part-of-speech> pizza.","title":"Example"},{"location":"CCML/#domain","text":"Applies different speaking styles to the speech. The styles are curated text-to-speech voices that use different variations of intonation, emphasis, pausing, and other techniques to match the speech to the content.","title":"&lt;domain&gt;"},{"location":"CCML/#channels-supported_11","text":"Amazon Alexa ZOOM","title":"Channels Supported"},{"location":"CCML/#attributes_8","text":"name - conversational \u2013 Style voices to sound more conversational and less formal, more like how people sound when they speak to friends and family. The conversational style is available in English (US), Italian (IT), and Japanese (JP) skills. You can also use this style with Amazon Polly voices. For Amazon Polly, conversational requires the <voice> tag and the Matthew or Joanna voices. long-form \u2013 Style the speech for long-form content such as podcasts, articles, and blogs. The long-form style can't be used with the voice tag. The long-form style is available in English (US) skills. music \u2013 Style the speech for talking about music, video, or other multi-media content. The music style can't be used with the voice tag. The music style is available in English (US), English (CA), and English (UK) skills. news \u2013 Style the speech similar to what you hear when listening to the news on the radio or television. The news style can be combined with the voice tag and the Matthew, Joanna, and Lupe voices. The news style is available in English (US) and English (AU) skills.","title":"Attributes"},{"location":"CCML/#example_10","text":"<domain name=\"news\"> Here are the latest new about conversational AI and voice. </domain>","title":"Example"},{"location":"CCML/#effect","text":"Applies specific effects to the speech.","title":"&lt;effect&gt;"},{"location":"CCML/#channels-supported_12","text":"Amazon Alexa ZOOM","title":"Channels Supported"},{"location":"CCML/#attributes_9","text":"name - whispered - Applies a whispering effect to the speech.","title":"Attributes"},{"location":"CCML/#example_11","text":"<effect name=\"whispered\">I am whispering this.</effect>","title":"Example"},{"location":"CCML/#emotion","text":"The emotion tag causes Alexa to express emotion when speaking.","title":"&lt;emotion&gt;"},{"location":"CCML/#channels-supported_13","text":"Amazon Alexa ZOOM","title":"Channels Supported"},{"location":"CCML/#attributes_10","text":"name - The name of the emotion to apply to the speech. - excited disappointed intensity - The intensity or strength of the emotion to express. - low medium high","title":"Attributes"},{"location":"CCML/#example_12","text":"<emotion name=\"excited\" intensity=\"high\"> This is unbelievable! </emotion>","title":"Example"},{"location":"CCML/#speak","text":"This is the root element of an SSML document.","title":"&lt;speak&gt;"},{"location":"CCML/#channels-supported_14","text":"Amazon Alexa Google Assistant ZOOM","title":"Channels Supported"},{"location":"CCML/#example_13","text":"<speak> SSML content </speak>","title":"Example"},{"location":"CCML/#audio","text":"The audio tag lets you provide the URL for an MP3 file that the service can play while rendering a response.","title":"&lt;audio&gt;"},{"location":"CCML/#channels-supported_15","text":"Amazon Alexa Google Assistant ZOOM","title":"Channels Supported"},{"location":"CCML/#attributes_11","text":"src - A URI referring to the audio media source. Supported protocol is https.","title":"Attributes"},{"location":"CCML/#example_14","text":"<audio src=\"https://some-url.com/soundfile.mp3\" />","title":"Example"},{"location":"CCML/#mark","text":"An empty element that places a marker into the text or tag sequence. It can be used to reference a specific location in the sequence or to insert a marker into an output stream for asynchronous notification.","title":"&lt;mark&gt;"},{"location":"CCML/#channels-supported_16","text":"Google Assistant","title":"Channels Supported"},{"location":"CCML/#attributes_12","text":"name - Mark name.","title":"Attributes"},{"location":"CCML/#example_15","text":"Go from <mark name=\"here\"/> here, to <mark name=\"there\"/> there!","title":"Example"},{"location":"CCML/#media","text":"Represents a media layer within a <parallel> or <sequential> element. The allowed content of a <media> element is an SSML <speak> or <audio> element. The following table describes the valid attributes for a <media> element.","title":"&lt;media&gt;"},{"location":"CCML/#channels-supported_17","text":"Google Assistant","title":"Channels Supported"},{"location":"CCML/#attributes_13","text":"xml:id - A unique XML identifier for this element. Encoded entities are not supported. The allowed identifier values match the regular expression \"([-_#]|\\p{L}|\\p{D})+\". See XML-ID for more information. begin - The beginning time for this media container. Ignored if this is the root media container element (treated the same as the default of \"0\"). See the Time specification section below for valid string values. end - A specification for the ending time for this media container. See the Time specification section below for valid string values. repeatCount - A Real Number specifying how many times to insert the media. Fractional repetitions aren't supported, so the value will be rounded to the nearest integer. Zero is not a valid value and is therefore treated as being unspecified and has the default value in that case. repeatDur - A TimeDesignation that is a limit on the duration of the inserted media. If the duration of the media is less than this value, then playback ends at that time. soundLevel - Adjust the sound level of the audio by soundLevel decibels. Maximum range is +/-40dB but actual range may be effectively less, and output quality may not yield good results over the entire range. fadeInDur - A TimeDesignation over which the media will fade in from silent to the optionally-specified soundLevel. If the duration of the media is less than this value, the media will be mid-fade in at the end of playback. fadeOutDur - A TimeDesignation over which the media will fade out from the optionally-specified soundLevel until it is silent. If the duration of the media is less than this value, the media will be mid-fade out at the beginning of playback.","title":"Attributes"},{"location":"CCML/#example_16","text":"<media xml:id=\"question\" begin=\"0.5s\"> <speak>Who invented the Internet?</speak> </media>","title":"Example"},{"location":"CCML/#parallel","text":"A parallel media container that allows you to play multiple media elements at once. The only allowed content is a set of one or more <parallel>, <sequential>, and <media> elements. The order of the <media> elements is not significant.","title":"&lt;parallel&gt;"},{"location":"CCML/#channels-supported_18","text":"Google Assistant","title":"Channels Supported"},{"location":"CCML/#example_17","text":"<parallel> <media xml:id=\"question\" begin=\"0.5s\"> <speak>Who invented the Internet?</speak> </media> <media xml:id=\"answer\" begin=\"question.end+2.0s\"> <speak>The Internet was invented by cats.</speak> </media> </parallel>","title":"Example"},{"location":"CCML/#sequential","text":"A sequential media container that allows you to play media elements one after another. The only allowed content is a set of one or more <sequential>, <parallel>, and <media> elements. The order of the media elements is the order in which they are rendered.","title":"&lt;sequential&gt;"},{"location":"CCML/#channels-supported_19","text":"Google Assistant","title":"Channels Supported"},{"location":"CCML/#example_18","text":"<sequential> <media begin=\"0.5s\"> <speak>Who invented the Internet?</speak> </media> <media begin=\"2.0s\"> <speak>The Internet was invented by cats.</speak> </media> </sequential>","title":"Example"},{"location":"SDKs/","text":"Python ( github ) NodeJS ( github ) Rasa ( github ) Cognigy ( github )","title":"SDKs"},{"location":"SDKs/#python","text":"( github )","title":"Python"},{"location":"SDKs/#nodejs","text":"( github )","title":"NodeJS"},{"location":"SDKs/#rasa","text":"( github )","title":"Rasa"},{"location":"SDKs/#cognigy","text":"( github )","title":"Cognigy"},{"location":"api/","text":"window.onload = function () { // Begin Swagger UI call region const ui = SwaggerUIBundle({ url: \"/openapi.yaml\", //Location of Open API spec in the repo dom_id: '#swagger-ui', deepLinking: true, presets: [ SwaggerUIBundle.presets.apis, SwaggerUIBundle.SwaggerUIStandalonePreset ], plugins: [ SwaggerUIBundle.plugins.DownloadUrl ], }) window.ui = ui }","title":"Api"},{"location":"connectors/","text":"Toolkits to expose components with our unified API Dialogflow ( github ) Rasa ( github ) Cognigy ( github ) Houndify ( github )","title":"Vendor Toolkits"},{"location":"connectors/#dialogflow","text":"( github )","title":"Dialogflow"},{"location":"connectors/#rasa","text":"( github )","title":"Rasa"},{"location":"connectors/#cognigy","text":"( github )","title":"Cognigy"},{"location":"connectors/#houndify","text":"( github )","title":"Houndify"},{"location":"vendor-guidelines/","text":"The component should address a single task or conversation topic The component must comply with the CoCo API, terms and conditions The component must be able to manage the calls to and from the component (control protocol) The component must use the context/updated_context/context transfer standard correctly The vendor should provide a clear description and goal of the component The component must be be available for calls 24/7. Minimum uptime of over 95%. The Component must be self-contained - handle the conversation from beginning to end Parameters passed by the component must be relevant to the component\u2019s goal The Component should be able to understand inputs which are relevant to the component goal (within reason), and identify inputs not relevant to the component goal The vendor must expose all bot responses for lingual customization The component must be GDPR compliant.","title":"Publishing guidelines"},{"location":"concepts/context/","text":"General Context refers to the the short-term memory maintained during the current session. The memory is in the form of key-value pairs with nested structes. It usually contains information about the user or information relating to the goal of the component. A calling agent can pass context key-values to a component on every turn and the response includes updated context key-values. At the end of a session with a component the final context holds the last version of each datapoint gathered in the conversation and can be used as structured data for other components.","title":"Context"},{"location":"concepts/context/#general","text":"Context refers to the the short-term memory maintained during the current session. The memory is in the form of key-value pairs with nested structes. It usually contains information about the user or information relating to the goal of the component. A calling agent can pass context key-values to a component on every turn and the response includes updated context key-values. At the end of a session with a component the final context holds the last version of each datapoint gathered in the conversation and can be used as structured data for other components.","title":"General"},{"location":"concepts/convcomp/","text":"General A conversational component is a part of the conversation where an agent (virtual/real) takes over the conversation in order to accomplish one or more goals. Upon accomplishing the goal, the agent (virtual/real) relinquishes control of the conversation back to the calling agent. Each component is defined by the goal or goals it is attempting to solve. Conversational components are architected to be modular Entries A component may be called at any point in the conversation so it needs to be ready to assume control of an existing conversation or, alternately, initiate a conversation. Every component needs to decide how to handle the conversation history it inherits - if any. Terminating a component Each component can signal the calling agent to stop calling it at any point. Usually it will send the signal along with information about the component's stated goal: 1. component_done: The Component accomplished the stated goal 2. component_failed: The Component didn't accomplish the stated goal Going out of context Sometimes when a user is talking to a component, he/she will ask questions which are outside the domain of the component (Out of Context) There are several options for this scenarion: one way to handle it is to relinquish control back to the calling agent for one turn (to answer the non-contextual question) and then resume control immediately after providing the relevant response. In CoCo this signal is called \"out_of_context\" CoCo API Specs","title":"Conversational Component"},{"location":"concepts/convcomp/#general","text":"A conversational component is a part of the conversation where an agent (virtual/real) takes over the conversation in order to accomplish one or more goals. Upon accomplishing the goal, the agent (virtual/real) relinquishes control of the conversation back to the calling agent. Each component is defined by the goal or goals it is attempting to solve. Conversational components are architected to be modular","title":"General"},{"location":"concepts/convcomp/#entries","text":"A component may be called at any point in the conversation so it needs to be ready to assume control of an existing conversation or, alternately, initiate a conversation. Every component needs to decide how to handle the conversation history it inherits - if any.","title":"Entries"},{"location":"concepts/convcomp/#terminating-a-component","text":"Each component can signal the calling agent to stop calling it at any point. Usually it will send the signal along with information about the component's stated goal: 1. component_done: The Component accomplished the stated goal 2. component_failed: The Component didn't accomplish the stated goal","title":"Terminating a component"},{"location":"concepts/convcomp/#going-out-of-context","text":"Sometimes when a user is talking to a component, he/she will ask questions which are outside the domain of the component (Out of Context) There are several options for this scenarion: one way to handle it is to relinquish control back to the calling agent for one turn (to answer the non-contextual question) and then resume control immediately after providing the relevant response. In CoCo this signal is called \"out_of_context\"","title":"Going out of context"},{"location":"concepts/convcomp/#coco-api-specs","text":"","title":"CoCo API Specs"},{"location":"concepts/goals/","text":"General Conversation is an interactive communication between two or more agents (virtual or real). Each agent has their own agenda and goals. The typical framing of a reinforcement learning scenario from each agent's point of view is such: His environment is the other agent's which he observes and interprets to build his model of the world He maintains state - his memory is based on previous observations and his model of the world He performs actions based on his state in the environment in order to achieve his goals Note In a learned agent each action is paired with a reward. The agent agenda and goals are defined by these rewards.","title":"Goals"},{"location":"concepts/goals/#general","text":"Conversation is an interactive communication between two or more agents (virtual or real). Each agent has their own agenda and goals. The typical framing of a reinforcement learning scenario from each agent's point of view is such: His environment is the other agent's which he observes and interprets to build his model of the world He maintains state - his memory is based on previous observations and his model of the world He performs actions based on his state in the environment in order to achieve his goals Note In a learned agent each action is paired with a reward. The agent agenda and goals are defined by these rewards.","title":"General"},{"location":"landing/devs/","text":"Chatbot Developers CoCoHub lets you find hosted, community-built conversational components for your bot. We index a diverse set of components, measure their availability and make them searchable, all to make it easy to find the perfect component for the task. In addition, our set of standards and SDKs make the integration work simple. You can use the existing integration for most instances or integrate once and get access to all of the components published on CoCoHub. Each component is meant to fulfill a specific purpose; for example, getting a piece of information from the user, helping the user accomplish a certain task, entertaining the user, or informing them of new and relevant information. You can call components through a simple unified, REST API that is easy to embed in your chatbot. Moreover, you can view all of the components you are using in your workspace, which monitors the number of API requests, latency, and error rates, among other metrics. Start Now: Check out how guides on how to use components in your platform of choice: link Start from scratch using one of our templates with integrations already working: link Explore CoCoHub to get ideas of what kind of components you can use: link Learn how to publish your own component: link to vendors page","title":"Chatbot Developers"},{"location":"landing/devs/#chatbot-developers","text":"CoCoHub lets you find hosted, community-built conversational components for your bot. We index a diverse set of components, measure their availability and make them searchable, all to make it easy to find the perfect component for the task. In addition, our set of standards and SDKs make the integration work simple. You can use the existing integration for most instances or integrate once and get access to all of the components published on CoCoHub. Each component is meant to fulfill a specific purpose; for example, getting a piece of information from the user, helping the user accomplish a certain task, entertaining the user, or informing them of new and relevant information. You can call components through a simple unified, REST API that is easy to embed in your chatbot. Moreover, you can view all of the components you are using in your workspace, which monitors the number of API requests, latency, and error rates, among other metrics.","title":"Chatbot Developers"},{"location":"landing/devs/#start-now","text":"Check out how guides on how to use components in your platform of choice: link Start from scratch using one of our templates with integrations already working: link Explore CoCoHub to get ideas of what kind of components you can use: link Learn how to publish your own component: link to vendors page","title":"Start Now:"},{"location":"landing/vendors/","text":"For Component Vendors CoCoHub lets you host and share your work with the chatbot builder community. We have the biggest repository for hosted conversational components in the world! Each component is intended to achieve a specific purpose; for example getting a piece of information from the user, help the user accomplish some task, entertain the user, or inform them of some relevant information. If you\u2019ve already built an intelligent bot of your own, we make it simple for you to distribute and monetize parts of it. Adding your component to CoCoHub has many advantages; You\u2019ll get instant exposure to our growing user base, a search-engine-optimized profile page for your component, as well as features like user management and billing services. Start now: Check out our toolkits to connect popluar platforms to CoCoHub: link Learn more about the API and how to connect new platforms: link","title":"For Component Vendors"},{"location":"landing/vendors/#for-component-vendors","text":"CoCoHub lets you host and share your work with the chatbot builder community. We have the biggest repository for hosted conversational components in the world! Each component is intended to achieve a specific purpose; for example getting a piece of information from the user, help the user accomplish some task, entertain the user, or inform them of some relevant information. If you\u2019ve already built an intelligent bot of your own, we make it simple for you to distribute and monetize parts of it. Adding your component to CoCoHub has many advantages; You\u2019ll get instant exposure to our growing user base, a search-engine-optimized profile page for your component, as well as features like user management and billing services.","title":"For Component Vendors"},{"location":"landing/vendors/#start-now","text":"Check out our toolkits to connect popluar platforms to CoCoHub: link Learn more about the API and how to connect new platforms: link","title":"Start now:"},{"location":"tutorials/alexa_skill_from_scratch/","text":"Steps: Choose one or more relevant components, using Cocohub's Bot Studio editor. Create a new Alexa Skill on CoCoHub's Alexa Skill Service. Configure your Alexa Skill. Get A Component As an example we'll create an Alexa Word Game Skill: Go to CoCoHub , sign Up and click Bot Studio on the left sidebar. Create a new component from the \"Word Games\" Template. Create Alexa Skill On Alexa Skill Service Press \"Channels\" on the app-bar. Choose \"Alexa\". Fill in the following fields: Polly Voice ID : The voice which the skill will use. Here are the available voices: Available Voices . End Statement : Skill response when users wishes to end the skill. Help Statement : Skill response will be returned on AMAZON. Help intent. Reprompt Statement : Will be skill's response when user did not response. Skill Invocation Name : The phrase which will invoke the skill. e.g. Alexa, open Jeopardy Configure Your Alexa Skill (At the Alexa Developer Console ) Place the generated endpoint url at the endpoint section. Upload the Skill JSON Editor.(Intents -> JSON Editor)","title":"Alexa skill from scratch"},{"location":"tutorials/alexa_skill_from_scratch/#steps","text":"Choose one or more relevant components, using Cocohub's Bot Studio editor. Create a new Alexa Skill on CoCoHub's Alexa Skill Service. Configure your Alexa Skill.","title":"Steps:"},{"location":"tutorials/alexa_skill_from_scratch/#get-a-component","text":"As an example we'll create an Alexa Word Game Skill: Go to CoCoHub , sign Up and click Bot Studio on the left sidebar. Create a new component from the \"Word Games\" Template.","title":"Get A Component"},{"location":"tutorials/alexa_skill_from_scratch/#create-alexa-skill-on-alexa-skill-service","text":"Press \"Channels\" on the app-bar. Choose \"Alexa\". Fill in the following fields: Polly Voice ID : The voice which the skill will use. Here are the available voices: Available Voices . End Statement : Skill response when users wishes to end the skill. Help Statement : Skill response will be returned on AMAZON. Help intent. Reprompt Statement : Will be skill's response when user did not response. Skill Invocation Name : The phrase which will invoke the skill. e.g. Alexa, open Jeopardy","title":"Create Alexa Skill On Alexa Skill Service"},{"location":"tutorials/alexa_skill_from_scratch/#configure-your-alexa-skill-at-the-alexa-developer-console","text":"Place the generated endpoint url at the endpoint section. Upload the Skill JSON Editor.(Intents -> JSON Editor)","title":"Configure Your Alexa Skill (At the Alexa Developer Console)"},{"location":"tutorials/authors_videos/","text":"Building a component on Rasa Create a conversational component using Rasa Building a component on Dialogflow Create a conversational component using Dialogflow Building a component on Cognigy Create a conversational component using Cognigy. How to become a Vendor and submit a new CoCo","title":"Vendors"},{"location":"tutorials/authors_videos/#building-a-component-on-rasa","text":"Create a conversational component using Rasa","title":"Building a component on Rasa"},{"location":"tutorials/authors_videos/#building-a-component-on-dialogflow","text":"Create a conversational component using Dialogflow","title":"Building a component on Dialogflow"},{"location":"tutorials/authors_videos/#building-a-component-on-cognigy","text":"Create a conversational component using Cognigy.","title":"Building a component on Cognigy"},{"location":"tutorials/authors_videos/#how-to-become-a-vendor-and-submit-a-new-coco","text":"","title":"How to become a Vendor and submit a new CoCo"},{"location":"tutorials/developer_videos/","text":"Add a fallback CoCo to your Rasa bot How to integrate a Conversational Component (CoCo) in the Rasa Fallback trigger. Calling a CoCo from a Rasa bot Calling a CoCo from a Cognigy bot Use multiple CoCos in a Cognigy bot","title":"Developers"},{"location":"tutorials/developer_videos/#add-a-fallback-coco-to-your-rasa-bot","text":"How to integrate a Conversational Component (CoCo) in the Rasa Fallback trigger.","title":"Add a fallback CoCo to your Rasa bot"},{"location":"tutorials/developer_videos/#calling-a-coco-from-a-rasa-bot","text":"","title":"Calling a CoCo from a Rasa bot"},{"location":"tutorials/developer_videos/#calling-a-coco-from-a-cognigy-bot","text":"","title":"Calling a CoCo from a Cognigy bot"},{"location":"tutorials/developer_videos/#use-multiple-cocos-in-a-cognigy-bot","text":"","title":"Use multiple CoCos in a Cognigy bot"},{"location":"tutorials/facebook_channel/","text":"Requirements A Facebook Page Deployment Go to CoCohub's Facebook Channel. Login with Facebook. Select the page(s) that you would like to connect to a component. Paste the component ID in the Component ID field of the target page. Save the changes. Give it a try!","title":"Connect your component to facebook"},{"location":"tutorials/facebook_channel/#requirements","text":"A Facebook Page","title":"Requirements"},{"location":"tutorials/facebook_channel/#deployment","text":"Go to CoCohub's Facebook Channel. Login with Facebook. Select the page(s) that you would like to connect to a component. Paste the component ID in the Component ID field of the target page. Save the changes. Give it a try!","title":"Deployment"},{"location":"tutorials/manychat1/","text":"Use a conversational component in ManyChat At the following tutorial we'll create a flow for ManyChat that will implement Get Name component in it. Link to the final flow: namer_flow Create New Flow Choose Flows at the menu. Press On create flow at the right top corner. Create Action With External Request Create HTTP Request Action Create Action: Choose HTTP Request Action: Configure Action Request Link https://cocohub.ai/api/exchange/ [ CoCo Component ID ] / [ User ID ] Choose Component from CoCoHub . User ManyChat variable user_id. Request Body Use ManyChat Last Text Input variable {\"user_input\": [ Last Text Input ]} Parse Response Parse component response, extract the following variables: component_done - Boolean - True/False depends on if component complete it's goal. component_response - Text - Bot response. Send Component Response And Wait For User Replay. Create new node called Send Message . Choose user input feature at the node: Place component response variable as a bot message: Set Condition Set condition to check if the component done with it's purpose. If not redirect back to the HTTP request action. Create Condition: Set condition for component_done variable is false: Publish & Test Publish: Test:","title":"Add component to you ManyChat flow"},{"location":"tutorials/manychat1/#use-a-conversational-component-in-manychat","text":"At the following tutorial we'll create a flow for ManyChat that will implement Get Name component in it. Link to the final flow: namer_flow","title":"Use a conversational component in ManyChat"},{"location":"tutorials/manychat1/#create-new-flow","text":"Choose Flows at the menu. Press On create flow at the right top corner.","title":"Create New Flow"},{"location":"tutorials/manychat1/#create-action-with-external-request","text":"","title":"Create Action With External Request"},{"location":"tutorials/manychat1/#create-http-request-action","text":"Create Action: Choose HTTP Request Action:","title":"Create HTTP Request Action"},{"location":"tutorials/manychat1/#configure-action","text":"","title":"Configure Action"},{"location":"tutorials/manychat1/#request-link","text":"https://cocohub.ai/api/exchange/ [ CoCo Component ID ] / [ User ID ] Choose Component from CoCoHub . User ManyChat variable user_id.","title":"Request Link"},{"location":"tutorials/manychat1/#request-body","text":"Use ManyChat Last Text Input variable {\"user_input\": [ Last Text Input ]}","title":"Request Body"},{"location":"tutorials/manychat1/#parse-response","text":"Parse component response, extract the following variables: component_done - Boolean - True/False depends on if component complete it's goal. component_response - Text - Bot response.","title":"Parse Response"},{"location":"tutorials/manychat1/#send-component-response-and-wait-for-user-replay","text":"Create new node called Send Message . Choose user input feature at the node: Place component response variable as a bot message:","title":"Send Component Response And Wait For User Replay."},{"location":"tutorials/manychat1/#set-condition","text":"Set condition to check if the component done with it's purpose. If not redirect back to the HTTP request action. Create Condition: Set condition for component_done variable is false:","title":"Set Condition"},{"location":"tutorials/manychat1/#publish-test","text":"Publish: Test:","title":"Publish &amp; Test"},{"location":"tutorials/map_dialogFlow_intent_to_component/","text":"Map DialogFlow Intent To Component In the following tutorial we'll add a component into Dialogflow . The component will be triggered when a relevant intent matches. More specifically, we'll use the register component from the Hub . Here's what the end result looks like: Steps: Choose one or more relevant components using CoCoHub's Bot Studio editor. Create a new agent on CoCoHub's Dialogflow Service. Import CoCo intent from dedicated ZIP (Available on agent tag from the step above). Enable webhook in the Fulfillment section and set the url to be the endpoint from the steps above. Enable webhook call on the target intent. Get a component. Go to CoCoHub , sign Up. We'll use the register component register component Create Dialogflow Agent On CoCoHub's Dialogflow Service Press the \"Add An Agent\" button. Press the \"Add Intent/Component Pair\" to map the intent name to the component ID. Import ZIP CoCo Intent To Your Agent Download the intent ZIP file from the dialogflow service. Go to Agent settings. Go to \"Export And Import\". Press Import and choose the downloaded ZIP file. Enable webhook in the Fulfillment Section Go to the Fulfillment section. Press on enable webhook. Set the url to be the endpoint from the dialogflow CoCoHub's service. Enable webhook call On The Target Intent. Go to the target intent. Scroll to the bottom and press the enable webhook call.","title":"Map DialogFlow Intent To Component"},{"location":"tutorials/map_dialogFlow_intent_to_component/#map-dialogflow-intent-to-component","text":"In the following tutorial we'll add a component into Dialogflow . The component will be triggered when a relevant intent matches. More specifically, we'll use the register component from the Hub . Here's what the end result looks like:","title":"Map DialogFlow Intent To Component"},{"location":"tutorials/map_dialogFlow_intent_to_component/#steps","text":"Choose one or more relevant components using CoCoHub's Bot Studio editor. Create a new agent on CoCoHub's Dialogflow Service. Import CoCo intent from dedicated ZIP (Available on agent tag from the step above). Enable webhook in the Fulfillment section and set the url to be the endpoint from the steps above. Enable webhook call on the target intent.","title":"Steps:"},{"location":"tutorials/map_dialogFlow_intent_to_component/#get-a-component","text":"Go to CoCoHub , sign Up. We'll use the register component register component","title":"Get a component."},{"location":"tutorials/map_dialogFlow_intent_to_component/#create-dialogflow-agent-on-cocohubs-dialogflow-service","text":"Press the \"Add An Agent\" button. Press the \"Add Intent/Component Pair\" to map the intent name to the component ID.","title":"Create Dialogflow Agent On CoCoHub's Dialogflow Service"},{"location":"tutorials/map_dialogFlow_intent_to_component/#import-zip-coco-intent-to-your-agent","text":"Download the intent ZIP file from the dialogflow service. Go to Agent settings. Go to \"Export And Import\". Press Import and choose the downloaded ZIP file.","title":"Import ZIP CoCo Intent To Your Agent"},{"location":"tutorials/map_dialogFlow_intent_to_component/#enable-webhook-in-the-fulfillment-section","text":"Go to the Fulfillment section. Press on enable webhook. Set the url to be the endpoint from the dialogflow CoCoHub's service.","title":"Enable webhook in the Fulfillment Section"},{"location":"tutorials/map_dialogFlow_intent_to_component/#enable-webhook-call-on-the-target-intent","text":"Go to the target intent. Scroll to the bottom and press the enable webhook call.","title":"Enable webhook call On The Target Intent."},{"location":"tutorials/rasa/","text":"","title":"Rasa"},{"location":"tutorials/use_a_component_with_dialogflow_external/","text":"Calling a CoCo from Dialogflow (Externally) In the following tutorial we'll build a banking bot, using Dialogflow banking prebuilt agent and CoCo the 'Register' component from the CoCo Marketplace . I'll guide you thorough the whole process, including the implementation of the CoCo 'Register' component. Setup Prebuilt Bot On Dialogflow: Create a Dialogflow account. Go to the prebuilt agents menu: Choose banking agent: Import banking agent: Authentication With Dialogflow(Service Account Key): Extract agent service account key: Go to agent settings. Go to service accounts: Generate JSON key: Place it in code sample directory as service_accout.json: Code Sample Overview: We'll use a Flask application to expose our bot throut an API. For communication with Dialogflow we'll use Dialogflow SDK and for communication with the CoCo component we'll use CoCo SDK. Code to code sample repository: https://github.com/ConversationalComponents/webinar/tree/master/py Flow: Global Variable current_comp: MAIN_COMP = \"default\" # Current component on which the session is running. current_comp = MAIN_COMP The current_comp global variable will be \"default\" when the conversation is controlled by Dialogflow. When the control is passed to a CoCo component the value of the current_comp variable will be the CoCo component ID which is in control of the conversation right now. CoCo And Dialogflow Access Functions: Dialogflow and CoCo request wrapped with process functions. Let's take a look at the process_dialogflow function: def process_dialogflow ( session_id , text , language_code = \"en\" ): \"\"\" Returns bot output for user input. Using the same `session_id` between requests allows continuation of the conversation. Arguments: session_id (string): Current session ID. text (string): User input. language_code (string): Context language. Returns: Return tuple intent_name, bot_output (tuple). \"\"\" session = session_client . session_path ( project_id , session_id ) text_input = dialogflow . types . TextInput ( text = text , language_code = language_code ) query_input = dialogflow . types . QueryInput ( text = text_input ) response = session_client . detect_intent ( session = session , query_input = query_input ) return response . query_result . intent . display_name , response . query_result . fulfillment_text The function receives the session_id and user input then returns intent display name and response text. And there is the process_coco function: def process_coco ( component_id , session_id , input_text ): \"\"\" Process user input at a coco component. Arguments: component_id (string): Target component ID. session_id (string): Target session ID. input_text (string): User input text. Returns: CoCo component output. (string) \"\"\" component = ConversationalComponent ( component_id ) return component ( session_id = session_id , user_input = input_text ) The function receives CoCo component ID, session ID and user input. The answer will be the component output. /input Endpoint: At the our app.py file we will implement /input endpoint, which will receive user_input at the payload process the input and return bot response.(Will be implemented at the \"implement Component In Conversation Flow\" topic.) Choose And Add Component: Access marketplace: https://marketplace.conversationalcomponents.com/ Choose the 'Register' component: Add Component: Implement Component In Conversation Flow: @app . route ( \"/input\" , methods = [ \"POST\" ]) def get_input (): global current_comp request_data = request . get_json () or {} user_input = request_data . get ( \"user_input\" ) Send user input to Dialogflow. # Get response from DialogFlow for user input. intent_name , bot_output = process_dialogflow ( session_id = CURRENT_SESSION_ID , text = user_input ) Choose a relevant intent which will trigger the control pass to a CoCo component: The relevant intent for registration is \"account.open\". # If catch intent, give control to CoCo component. if intent_name == \"account.open\" : current_comp = \"register_vp3\" if current_comp == \"register_vp3\" : # Fetch response from CoCo if intent catch. coco_response = process_coco ( component_id = \"register_vp3\" , session_id = CURRENT_SESSION_ID , input_text = user_input ) When component is done, pass the conversation control back to Dialogflow: # If component done, return the control to the main flow. if coco_response . component_done : current_comp = MAIN_COMP bot_output = coco_response . response return jsonify ({ \"response\" : bot_output }), 200 , {} Run And Test The Bot: pip install -r requirements.txt flask run try the bot at 127.0.0.1:5000","title":"Calling a CoCo from Dialogflow (Externally)"},{"location":"tutorials/use_a_component_with_dialogflow_external/#calling-a-coco-from-dialogflow-externally","text":"In the following tutorial we'll build a banking bot, using Dialogflow banking prebuilt agent and CoCo the 'Register' component from the CoCo Marketplace . I'll guide you thorough the whole process, including the implementation of the CoCo 'Register' component.","title":"Calling a CoCo from Dialogflow (Externally)"},{"location":"tutorials/use_a_component_with_dialogflow_external/#setup-prebuilt-bot-on-dialogflow","text":"Create a Dialogflow account. Go to the prebuilt agents menu: Choose banking agent: Import banking agent:","title":"Setup Prebuilt Bot On Dialogflow:"},{"location":"tutorials/use_a_component_with_dialogflow_external/#authentication-with-dialogflowservice-account-key","text":"Extract agent service account key: Go to agent settings. Go to service accounts: Generate JSON key: Place it in code sample directory as service_accout.json:","title":"Authentication With Dialogflow(Service Account Key):"},{"location":"tutorials/use_a_component_with_dialogflow_external/#code-sample-overview","text":"We'll use a Flask application to expose our bot throut an API. For communication with Dialogflow we'll use Dialogflow SDK and for communication with the CoCo component we'll use CoCo SDK. Code to code sample repository: https://github.com/ConversationalComponents/webinar/tree/master/py","title":"Code Sample Overview:"},{"location":"tutorials/use_a_component_with_dialogflow_external/#flow","text":"","title":"Flow:"},{"location":"tutorials/use_a_component_with_dialogflow_external/#global-variable-current_comp","text":"MAIN_COMP = \"default\" # Current component on which the session is running. current_comp = MAIN_COMP The current_comp global variable will be \"default\" when the conversation is controlled by Dialogflow. When the control is passed to a CoCo component the value of the current_comp variable will be the CoCo component ID which is in control of the conversation right now.","title":"Global Variable current_comp:"},{"location":"tutorials/use_a_component_with_dialogflow_external/#coco-and-dialogflow-access-functions","text":"Dialogflow and CoCo request wrapped with process functions. Let's take a look at the process_dialogflow function: def process_dialogflow ( session_id , text , language_code = \"en\" ): \"\"\" Returns bot output for user input. Using the same `session_id` between requests allows continuation of the conversation. Arguments: session_id (string): Current session ID. text (string): User input. language_code (string): Context language. Returns: Return tuple intent_name, bot_output (tuple). \"\"\" session = session_client . session_path ( project_id , session_id ) text_input = dialogflow . types . TextInput ( text = text , language_code = language_code ) query_input = dialogflow . types . QueryInput ( text = text_input ) response = session_client . detect_intent ( session = session , query_input = query_input ) return response . query_result . intent . display_name , response . query_result . fulfillment_text The function receives the session_id and user input then returns intent display name and response text. And there is the process_coco function: def process_coco ( component_id , session_id , input_text ): \"\"\" Process user input at a coco component. Arguments: component_id (string): Target component ID. session_id (string): Target session ID. input_text (string): User input text. Returns: CoCo component output. (string) \"\"\" component = ConversationalComponent ( component_id ) return component ( session_id = session_id , user_input = input_text ) The function receives CoCo component ID, session ID and user input. The answer will be the component output.","title":"CoCo And Dialogflow Access Functions:"},{"location":"tutorials/use_a_component_with_dialogflow_external/#input-endpoint","text":"At the our app.py file we will implement /input endpoint, which will receive user_input at the payload process the input and return bot response.(Will be implemented at the \"implement Component In Conversation Flow\" topic.)","title":"/input Endpoint:"},{"location":"tutorials/use_a_component_with_dialogflow_external/#choose-and-add-component","text":"Access marketplace: https://marketplace.conversationalcomponents.com/ Choose the 'Register' component: Add Component:","title":"Choose And Add Component:"},{"location":"tutorials/use_a_component_with_dialogflow_external/#implement-component-in-conversation-flow","text":"@app . route ( \"/input\" , methods = [ \"POST\" ]) def get_input (): global current_comp request_data = request . get_json () or {} user_input = request_data . get ( \"user_input\" ) Send user input to Dialogflow. # Get response from DialogFlow for user input. intent_name , bot_output = process_dialogflow ( session_id = CURRENT_SESSION_ID , text = user_input ) Choose a relevant intent which will trigger the control pass to a CoCo component: The relevant intent for registration is \"account.open\". # If catch intent, give control to CoCo component. if intent_name == \"account.open\" : current_comp = \"register_vp3\" if current_comp == \"register_vp3\" : # Fetch response from CoCo if intent catch. coco_response = process_coco ( component_id = \"register_vp3\" , session_id = CURRENT_SESSION_ID , input_text = user_input ) When component is done, pass the conversation control back to Dialogflow: # If component done, return the control to the main flow. if coco_response . component_done : current_comp = MAIN_COMP bot_output = coco_response . response return jsonify ({ \"response\" : bot_output }), 200 , {}","title":"Implement Component In Conversation Flow:"},{"location":"tutorials/use_a_component_with_dialogflow_external/#run-and-test-the-bot","text":"pip install -r requirements.txt flask run try the bot at 127.0.0.1:5000","title":"Run And Test The Bot:"},{"location":"tutorials/videos/","text":"Your first time on CoCoHub? Let's show you around a bit so you get familiar enough to go solo. Customizing Components Is So Simple You can customize the response texts of a Conversational Component to match your bot's language and personality. Let's take it a step further: Use a CoCo in your bot Build a new Component","title":"CoCoHub"},{"location":"tutorials/videos/#your-first-time-on-cocohub","text":"Let's show you around a bit so you get familiar enough to go solo.","title":"Your first time on CoCoHub?"},{"location":"tutorials/videos/#customizing-components-is-so-simple","text":"You can customize the response texts of a Conversational Component to match your bot's language and personality.","title":"Customizing Components Is So Simple"},{"location":"tutorials/videos/#lets-take-it-a-step-further","text":"Use a CoCo in your bot Build a new Component","title":"Let's take it a step further:"},{"location":"tutorials/wp_cocobot/","text":"Wordpress CoCoHub Tutorial In this tutorial we'll guide you through adding a chat window to a conversational bot on a Wordpress page as well as using CoCoHub visual editing tools to create your own bot from components. It's quick, easy, and lets you leverage powerful AI to engage your users. Installing CoCoHub plugin in Wordpress We'll start by opening our Wordpress dashboard, and selecting PLUGINS from the drawer. Click the ADD NEW button (marked in red oval). Search for CoCoHub in keywords, and click the INSTALL NOW button on the card (marked in red oval). Now we need to activate the plugin. Click the ACTIVATE button on the card. Great! The plugin is installed and activated. We still need to add the shortcode to the pages on which we would like our chat window to show. Let's go to a page in our Wordpress site and edit any field. Now add the [cocobot] shortcode and update the page. All done! If you navigate to the page you've just updated, you should see a chat window there. It's the interface to a Cocobot, the Conversational Components evangelist bot. You'll probably want to build your own bot, though, so let's get to that. Building a bot in CoCoHub Start by heading over to CoCoHub , and signing in or registering, if you're a first time user. Welcome! When you're ready, choose Bots Studio from the drawer, and click ADD to create a new bot. Now we should have something that looks like this: Glue works with Nodes and Links - nodes are containers for components, and links route conversation flow between components. Let's take a deeper look at the leftmost node: The gold star in the rightmost corner indicates that it's an Entry component. This is the first component the bot's user will converse with. There must always be an entry component in each Glue. The text field containing namer_vp3 is the components associated with this node. The default component is namer_vp3, but you can use any component from Cocohub here. Click on it to enter search mode. DRAG TO LINK button creates a link between nodes. We'll discuss this in greater detail below. This is what a couple of linked nodes look like. Incoming link from another node means that another node has an action on which conversation flow will route to this component. Outgoing link is a route from a node to a different one. This is what's created using the DRAG TO LINK button. Outgoing link controls allow you to change the outgoing link. The text field containing \"component done\" allows you to select the action on which routing to a different node will happen. The default action is \"component done\" - that is, when the component has achieved it's goal. You can also delete the link here. Non-entry node options is a menu of controls for a non-entry node - it allows you to set a node as entry or to delete it. Parameters is a collapsible field for components that have parameters associated with them. \"email_pv1\" component has them, and when expanded the parameters look like this: If an email is associated with your account, it'll be in the address field. This is the email address to which the results will be sent once the bot is finished. Warning If there is no email in the address field, you won't get the email! Last, but not least, the general Glue controls: Save and Undo buttons are only enabled if you can save or undo. Saving generates a new Glue ID, and resets the chat window. COPY GLUE ID button - copies the last saved Glue ID to your clipboard. Chat window is where you can talk to the latest saved version of your bot. Please note that if SAVE button is turned on, you have unsaved changes which will not be reflected in the chat. This bot will get the user's name, and when it's finished getting the name it'll also get the user's email address. Once all that is done, it'll send you an email with the user's details. Now we can save the changes ( SAVE button in the control panel ), and chat to our newly created bot in the chat window. Pro Tip Everything in Coco bots is made of components. The component for making a bot is called a Glue component - it glues other components together. Since a glue is also a component, you can use glue components as nodes in a glue! Nicely done! Time to use our new bot in the Cocohub Wordpress plugin. Let's save any changes we have, and click the COPY GLUE ID button. Now let's head back to Wordpress admin dashboard, and configure our plugin to use the Glued bot. Configuring CoCoHub Wordpress plugin Head over to Plugins, and click SETTINGS on CoCoHub plugin. Now we just to have to pass the ID of the Glue component we created into component-id or url field (marked in red oval), and click SAVE CHANGES. All done! Head back to the page to which you inserted [cocobot] shortcode, and chat with your Glued bot from the comfort of your Wordpress site. Or change the other settings first: Name is the name that'll appear in the header of your bot's chat window Bot Greeting is what the bot will say to user when the chat window fist loads Height and Width define the dimensions of your bot's chat window Is Fabless is a checkbox for whether the chat window has a close/open button or not. When it's on, the chat window cannot be closed. Chat-window is open by default is a checkbox for whether the chat window starts opened. Only relevant if Is Fabless is off. That concludes the tutotial. Hopefully it'll put you on the path to making awesome, useful, engaging and fantastic bots!","title":"Build a modular bot on wordpress"},{"location":"tutorials/wp_cocobot/#wordpress-cocohub-tutorial","text":"In this tutorial we'll guide you through adding a chat window to a conversational bot on a Wordpress page as well as using CoCoHub visual editing tools to create your own bot from components. It's quick, easy, and lets you leverage powerful AI to engage your users.","title":"Wordpress CoCoHub Tutorial"},{"location":"tutorials/wp_cocobot/#installing-cocohub-plugin-in-wordpress","text":"We'll start by opening our Wordpress dashboard, and selecting PLUGINS from the drawer. Click the ADD NEW button (marked in red oval). Search for CoCoHub in keywords, and click the INSTALL NOW button on the card (marked in red oval). Now we need to activate the plugin. Click the ACTIVATE button on the card. Great! The plugin is installed and activated. We still need to add the shortcode to the pages on which we would like our chat window to show. Let's go to a page in our Wordpress site and edit any field. Now add the [cocobot] shortcode and update the page. All done! If you navigate to the page you've just updated, you should see a chat window there. It's the interface to a Cocobot, the Conversational Components evangelist bot. You'll probably want to build your own bot, though, so let's get to that.","title":"Installing CoCoHub plugin in Wordpress"},{"location":"tutorials/wp_cocobot/#building-a-bot-in-cocohub","text":"Start by heading over to CoCoHub , and signing in or registering, if you're a first time user. Welcome! When you're ready, choose Bots Studio from the drawer, and click ADD to create a new bot. Now we should have something that looks like this: Glue works with Nodes and Links - nodes are containers for components, and links route conversation flow between components. Let's take a deeper look at the leftmost node: The gold star in the rightmost corner indicates that it's an Entry component. This is the first component the bot's user will converse with. There must always be an entry component in each Glue. The text field containing namer_vp3 is the components associated with this node. The default component is namer_vp3, but you can use any component from Cocohub here. Click on it to enter search mode. DRAG TO LINK button creates a link between nodes. We'll discuss this in greater detail below. This is what a couple of linked nodes look like. Incoming link from another node means that another node has an action on which conversation flow will route to this component. Outgoing link is a route from a node to a different one. This is what's created using the DRAG TO LINK button. Outgoing link controls allow you to change the outgoing link. The text field containing \"component done\" allows you to select the action on which routing to a different node will happen. The default action is \"component done\" - that is, when the component has achieved it's goal. You can also delete the link here. Non-entry node options is a menu of controls for a non-entry node - it allows you to set a node as entry or to delete it. Parameters is a collapsible field for components that have parameters associated with them. \"email_pv1\" component has them, and when expanded the parameters look like this: If an email is associated with your account, it'll be in the address field. This is the email address to which the results will be sent once the bot is finished. Warning If there is no email in the address field, you won't get the email! Last, but not least, the general Glue controls: Save and Undo buttons are only enabled if you can save or undo. Saving generates a new Glue ID, and resets the chat window. COPY GLUE ID button - copies the last saved Glue ID to your clipboard. Chat window is where you can talk to the latest saved version of your bot. Please note that if SAVE button is turned on, you have unsaved changes which will not be reflected in the chat. This bot will get the user's name, and when it's finished getting the name it'll also get the user's email address. Once all that is done, it'll send you an email with the user's details. Now we can save the changes ( SAVE button in the control panel ), and chat to our newly created bot in the chat window. Pro Tip Everything in Coco bots is made of components. The component for making a bot is called a Glue component - it glues other components together. Since a glue is also a component, you can use glue components as nodes in a glue! Nicely done! Time to use our new bot in the Cocohub Wordpress plugin. Let's save any changes we have, and click the COPY GLUE ID button. Now let's head back to Wordpress admin dashboard, and configure our plugin to use the Glued bot.","title":"Building a bot in CoCoHub"},{"location":"tutorials/wp_cocobot/#configuring-cocohub-wordpress-plugin","text":"Head over to Plugins, and click SETTINGS on CoCoHub plugin. Now we just to have to pass the ID of the Glue component we created into component-id or url field (marked in red oval), and click SAVE CHANGES. All done! Head back to the page to which you inserted [cocobot] shortcode, and chat with your Glued bot from the comfort of your Wordpress site. Or change the other settings first: Name is the name that'll appear in the header of your bot's chat window Bot Greeting is what the bot will say to user when the chat window fist loads Height and Width define the dimensions of your bot's chat window Is Fabless is a checkbox for whether the chat window has a close/open button or not. When it's on, the chat window cannot be closed. Chat-window is open by default is a checkbox for whether the chat window starts opened. Only relevant if Is Fabless is off. That concludes the tutotial. Hopefully it'll put you on the path to making awesome, useful, engaging and fantastic bots!","title":"Configuring CoCoHub Wordpress plugin"}]}